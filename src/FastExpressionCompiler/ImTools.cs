// <auto-generated/>
/*
The MIT License (MIT)

Copyright (c) 2016-2025 Maksim Volkau

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included 
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

// ReSharper disable once InconsistentNaming
#nullable disable

#if !NETSTANDARD2_0_OR_GREATER && !NET472
#define SUPPORTS_UNSAFE
#define SUPPORTS_CREATE_SPAN
#endif

#if LIGHT_EXPRESSION
namespace FastExpressionCompiler.LightExpression.ImTools;
#else
namespace FastExpressionCompiler.ImTools;
#endif

using System;
using System.Collections;
using System.Collections.Generic;
using System.Diagnostics;
using System.Text;
using System.Runtime.CompilerServices;
using System.Runtime.InteropServices;
using System.Diagnostics.CodeAnalysis;

#if NET8_0_OR_GREATER
using System.Runtime.Intrinsics;
#endif

using static SmallMap;

/// <summary>Helpers and polyfills for the missing things in the old .NET versions</summary>
public static class RefTools<T>
{
    /// <summary>Polyfill for the missing returning the `ref` in the failed search scenario.
    /// Note that the result is the `null` even for the struct `T`, so avoid the accessing its members without the check</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref T GetNullRef() =>
#if SUPPORTS_UNSAFE
        ref Unsafe.NullRef<T>();
#else
        ref _missing;
    internal static T _missing = default;
#endif
}

/// <summary>Wrapper for the array of the specific capacity and a separate count less or equal to this capacity </summary>
public struct SmallList<T>
{
    /// <summary>Array of items</summary>
    public T[] Items;
    /// <summary>The count of used items</summary>
    public int Count;

    /// <summary>Creating this stuff</summary>
    public SmallList(T[] items, int count)
    {
        Items = items;
        Count = count;
    }

    /// <summary>Creates the wrapper out of the items</summary>
    public SmallList(T[] items) : this(items, items.Length) { }

    /// <summary>Popping candy</summary>
    public void Pop() => --Count;
}

/// <summary>SmallList module he-he</summary>
public static class SmallList
{
    internal const int ForLoopCopyCount = 4;
    internal const int DefaultInitialCapacity = 4;

    [MethodImpl(MethodImplOptions.NoInlining)]
    internal static ref T ThrowIndexOutOfBounds<T>(int index, int count)
    {
        throw new IndexOutOfRangeException($"Index {index} is out of range of count {count} for SmallList<{typeof(T)},..>.");
    }

    [MethodImpl((MethodImplOptions)256)]
    internal static void Expand<T>(ref T[] items)
    {
        // `| 1` is for the case when the length is 0
        var newItems = new T[(items.Length << 1) | 1]; // have fun to guess the new length, ha-ha ;-P
        if (items.Length > ForLoopCopyCount)
            Array.Copy(items, newItems, items.Length);
        else
            for (var i = 0; i < items.Length; ++i)
                newItems[i] = items[i];
        items = newItems;
    }

    /// <summary>Appends the new default item at the end of the items. Assumes that `index lte items.Length`! 
    /// `items` should be not null</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref T AddDefaultToNotNullItemsAndGetRef<T>(ref T[] items, int index)
    {
        Debug.Assert(index <= items.Length);
        if (index == items.Length)
            Expand(ref items);
        return ref items[index];
    }

    /// <summary>Appends the new default item at the end of the items. Assumes that `index lte items.Length`, `items` may be null</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref T AddDefaultAndGetRef<T>(ref T[] items, int index, int initialCapacity = DefaultInitialCapacity)
    {
        if (items == null)
        {
            Debug.Assert(index == 0);
            items = new T[initialCapacity];
            return ref items[index];
        }

        Debug.Assert(index <= items.Length);
        if (index == items.Length)
            Expand(ref items);
        return ref items[index];
    }

    /// <summary>Returns surely present item ref by its index</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref T GetSurePresentItemRef<T>(this ref SmallList<T> source, int index) =>
        ref source.Items[index];

    /// <summary>Returns surely present item ref by its index without boundary checks</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref T GetSurePresentItemRef<T>(this T[] items, int index)
    {
#if SUPPORTS_UNSAFE
        return ref Unsafe.Add(ref MemoryMarshal.GetArrayDataReference(items), index);
#else
        return ref items[index];
#endif
    }

    // todo: @perf add the not null variant
    /// <summary>Appends the new default item to the list and returns ref to it for write or read</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref T Add<T>(this ref SmallList<T> source, int initialCapacity = DefaultInitialCapacity) =>
        ref AddDefaultAndGetRef(ref source.Items, source.Count++, initialCapacity);

    /// <summary>Appends the new item to the list</summary>
    // todo: @perf add the not null variant
    [MethodImpl((MethodImplOptions)256)]
    public static void Add<T>(this ref SmallList<T> source, in T item, int initialCapacity = DefaultInitialCapacity) =>
        AddDefaultAndGetRef(ref source.Items, source.Count++, initialCapacity) = item;

    /// <summary>Looks for the item in the list and return its index if found or -1 for the absent item</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static int TryGetIndex<T, TEq>(this T[] items, in T it, int startIndex, int count, TEq eq = default,
        int notFoundResult = -1)
        where TEq : struct, IEq<T>
    {
        Debug.Assert(items != null);
        for (var i = startIndex; i < count; ++i)
        {
            ref var di = ref items[i]; // todo: @perf Marshall?
            if (eq.Equals(it, di))
                return i;
        }
        return notFoundResult;
    }

    /// <summary>Looks for the item in the list and return its index if found or -1 for the absent item</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static int TryGetIndex<T, TEq>(this ref SmallList<T> source, T it, TEq eq = default)
        where TEq : struct, IEq<T>
        => source.Items.TryGetIndex(it, 0, source.Count, eq);

    /// <summary>Returns the index of the found item or appends the item to the end of the list, and returns its index</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static int GetIndexOrAdd<T, TEq>(this ref SmallList<T> source, in T item, TEq eq = default)
        where TEq : struct, IEq<T>
    {
        var count = source.Count;
        if (count != 0)
        {
            var index = TryGetIndex(source.Items, in item, 0, count, eq);
            if (index != -1)
                return index;
        }
        source.Add() = item;
        return count;
    }
}

#pragma warning disable CS9101 // UnscopedRef goes wrong on Ubuntu

/// <summary>Utilities for Stack4, Stack8, etc.</summary>
public static class Stack
{
    [MethodImpl(MethodImplOptions.NoInlining)]
    internal static ref T ThrowIndexOutOfBounds<T>(int index, int capacity) =>
        throw new IndexOutOfRangeException($"Index {index} is out of range for Stack{capacity}<{typeof(T)},..>.");
}

/// <summary>Stack with the Size information to check it at compile time</summary>
public interface IStack<T, TSize, TStack> : IStack<T, TStack>
    where TSize : struct, ISize
    where TStack : struct, IStack<T, TSize, TStack>
{
}

/// <summary>Abstracts over collection of the items on stack of the fixed Capacity,
/// to be used as a part of the hybrid data structures which grow from stack to heap</summary>
public interface IStack<T, TStack>
    where TStack : struct, IStack<T, TStack>
{
    /// <summary>Maximum count of items hold on stack</summary>
    int Capacity { get; }

    /// <summary>Returns the item by ref to read and write the item value,
    /// but does not check the index bounds comparing to the `this[index]`</summary>
    [UnscopedRef]
    ref T GetSurePresentItemRef(int index);

    /// <summary>Indexer returning the item by ref to read and write the item value</summary>
    [UnscopedRef]
    ref T this[int index] { get; }

#if SUPPORTS_CREATE_SPAN
    /// <summary>Creates a span over the stack items</summary>
    public Span<T> AsSpan();
#endif

}

// todo: @wip
/// <summary>Base marker for collection or container holding some number of items</summary>
public interface ISize
{
    /// <summary>Returns the size of the collection or container</summary>
    int Size { get; }
}
/// <summary>Marker for collection or container holding 2 or items</summary>
public interface ISize2Plus : ISize { }
/// <summary>Marker for collection or container holding 4 or more items</summary>
public interface ISize4Plus : ISize2Plus { }
/// <summary>Marker for collection or container holding 8 or more items</summary>
public interface ISize8Plus : ISize4Plus { }
/// <summary>Marker for collection or container holding 16 or more items</summary>
public interface ISize16Plus : ISize8Plus { }

/// <summary>Marker for collection or container holding 4 items</summary>
public struct Size2 : ISize2Plus
{
    /// <inheritdoc/>
    public int Size => 2;
}
/// <summary>Marker for collection or container holding 4 items</summary>
public struct Size4 : ISize4Plus
{
    /// <inheritdoc/>
    public int Size => 4;
}
/// <summary>Marker for collection or container holding 8 items</summary>
public struct Size8 : ISize8Plus
{
    /// <inheritdoc/>
    public int Size => 8;
}
/// <summary>Marker for collection or container holding 16 items</summary>
public struct Size16 : ISize16Plus
{
    /// <inheritdoc/>
    public int Size => 16;
}

/// <summary>Implementation of `IStack` for 2 items on stack</summary>
[StructLayout(LayoutKind.Sequential, Pack = 1)]
public struct Stack2<T> : IStack<T, Size2, Stack2<T>>
{
    /// <inheritdoc/>
    public int Capacity => 2;

    internal T _it0, _it1;

    /// <inheritdoc/>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref T GetSurePresentItemRef(int index)
    {
#if SUPPORTS_UNSAFE
        return ref Unsafe.Add(ref _it0, index);
#else
        switch (index)
        {
            case 0: return ref _it0;
            default: return ref _it1;
        }
#endif
    }

    /// <inheritdoc/>
    [UnscopedRef]
    public ref T this[int index]
    {
        [MethodImpl((MethodImplOptions)256)]
        get
        {
            if (index >= 0 & index < Capacity)
                return ref GetSurePresentItemRef(index);
            return ref Stack.ThrowIndexOutOfBounds<T>(index, Capacity);
        }
    }

#if SUPPORTS_CREATE_SPAN
    /// <inheritdoc/>
    [MethodImpl((MethodImplOptions)256)]
    public Span<T> AsSpan() => MemoryMarshal.CreateSpan(ref _it0, Capacity);
#endif
}

/// <summary>Implementation of `IStack` for 4 items on stack</summary>
[StructLayout(LayoutKind.Sequential, Pack = 1)]
public struct Stack4<T> : IStack<T, Size4, Stack4<T>>
{
    /// <inheritdoc/>
    public int Capacity => 4;

    internal T _it0, _it1, _it2, _it3;

    /// <inheritdoc/>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref T GetSurePresentItemRef(int index)
    {
#if SUPPORTS_UNSAFE
        return ref Unsafe.Add(ref _it0, index);
#else
        switch (index)
        {
            case 0: return ref _it0;
            case 1: return ref _it1;
            case 2: return ref _it2;
            default: return ref _it3;
        }
#endif
    }

    /// <inheritdoc/>
    [UnscopedRef]
    public ref T this[int index]
    {
        [MethodImpl((MethodImplOptions)256)]
        get
        {
            if (index >= 0 & index < Capacity)
                return ref GetSurePresentItemRef(index);
            return ref Stack.ThrowIndexOutOfBounds<T>(index, Capacity);
        }
    }

#if SUPPORTS_CREATE_SPAN
    /// <inheritdoc/>
    [MethodImpl((MethodImplOptions)256)]
    public Span<T> AsSpan() => MemoryMarshal.CreateSpan(ref _it0, Capacity);
#endif
}

/// <summary>Implementation of `IStack` for 8 items on stack</summary>
[StructLayout(LayoutKind.Sequential, Pack = 1)]
public struct Stack8<T> : IStack<T, Size8, Stack8<T>>
{
    /// <inheritdoc/>
    public int Capacity => 8;

    internal T _it0, _it1, _it2, _it3, _it4, _it5, _it6, _it7;

    /// <inheritdoc/>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref T GetSurePresentItemRef(int index)
    {
#if SUPPORTS_UNSAFE
        return ref Unsafe.Add(ref _it0, index);
#else
        switch (index)
        {
            case 0: return ref _it0;
            case 1: return ref _it1;
            case 2: return ref _it2;
            case 3: return ref _it3;
            case 4: return ref _it4;
            case 5: return ref _it5;
            case 6: return ref _it6;
            default: return ref _it7;
        }
#endif
    }

    /// <inheritdoc/>
    [UnscopedRef]
    public ref T this[int index]
    {
        [MethodImpl((MethodImplOptions)256)]
        get
        {
            if (index >= 0 & index < Capacity)
                return ref GetSurePresentItemRef(index);
            return ref Stack.ThrowIndexOutOfBounds<T>(index, Capacity);
        }
    }

#if SUPPORTS_CREATE_SPAN
    /// <inheritdoc/>
    [MethodImpl((MethodImplOptions)256)]
    public Span<T> AsSpan() => MemoryMarshal.CreateSpan(ref _it0, Capacity);
#endif
}

/// <summary>Implementation of `IStack` for 16 items on stack</summary>
[StructLayout(LayoutKind.Sequential, Pack = 1)]
public struct Stack16<T> : IStack<T, Size16, Stack16<T>>
{
    /// <inheritdoc/>
    public int Capacity => 16;

    internal T _it0, _it1, _it2, _it3, _it4, _it5, _it6, _it7;
    internal T _it8, _it9, _it10, _it11, _it12, _it13, _it14, _it15;

    /// <inheritdoc/>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref T GetSurePresentItemRef(int index)
    {
#if SUPPORTS_UNSAFE
        return ref Unsafe.Add(ref _it0, index);
#else
        switch (index)
        {
            case 0: return ref _it0;
            case 1: return ref _it1;
            case 2: return ref _it2;
            case 3: return ref _it3;
            case 4: return ref _it4;
            case 5: return ref _it5;
            case 6: return ref _it6;
            case 7: return ref _it7;
            case 8: return ref _it8;
            case 9: return ref _it9;
            case 10: return ref _it10;
            case 11: return ref _it11;
            case 12: return ref _it12;
            case 13: return ref _it13;
            case 14: return ref _it14;
            default: return ref _it15;
        }
#endif
    }

    /// <inheritdoc/>
    [UnscopedRef]
    public ref T this[int index]
    {
        [MethodImpl((MethodImplOptions)256)]
        get
        {
            if (index >= 0 & index < Capacity)
                return ref GetSurePresentItemRef(index);
            return ref Stack.ThrowIndexOutOfBounds<T>(index, Capacity);
        }
    }

#if SUPPORTS_CREATE_SPAN
    /// <inheritdoc/>
    [MethodImpl((MethodImplOptions)256)]
    public Span<T> AsSpan() => MemoryMarshal.CreateSpan(ref _it0, Capacity);
#endif
}

/// <summary>Generic version of SmallList abstracted for how much items are on the stack</summary>
public struct SmallList<T, TStack> : IEnumerable<T>
    where TStack : struct, IStack<T, TStack>
{
    /// <summary>Let's enable access to the Count, so you can Pop the item by --list.Count. Just don't forget to nullify the popped item if needed</summary>
    public int Count;

#pragma warning disable CS0649 // it is fine `Stack` is never assigned to, and will always have its default value
    /// <summary>Let's enable access to the stack, just know what's you doing</summary>
    public TStack Stack;
#pragma warning restore CS0649

    /// <summary>Exposes the rest on the heap</summary>
    public T[] Rest;

    /// <summary>Ensures that the list has allocated space to hold `count` of items</summary>
    [MethodImpl((MethodImplOptions)256)]
    public void InitCount(int count)
    {
        Debug.Assert(count > 0, "Count should be more than 0");
        Debug.Assert(Count == 0, "Initial the count should be 0");

        // Add the StackCapacity empty space at the end, we may use it later for BuildToArray.
        // The actual source Capacity will be StackCapacity + count.
        if (count > Stack.Capacity)
            Rest = new T[count];
        Count = count;
    }

    /// <summary>Returns surely present item by ref</summary>
    [UnscopedRef]
    public ref T this[int index]
    {
        [MethodImpl((MethodImplOptions)256)]
        get
        {
            if (index < 0 | index >= Count)
                return ref SmallList.ThrowIndexOutOfBounds<T>(index, Count);

            var stackCap = Stack.Capacity;
            if (index < stackCap)
                return ref Stack.GetSurePresentItemRef(index);

            Debug.Assert(Rest != null, "Expecting deeper items are already existing on heap");
            return ref Rest.GetSurePresentItemRef(index - stackCap);
        }
    }

    /// <summary>Returns a surely present item ref by its index</summary>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref T GetSurePresentItemRef(int index)
    {
        Debug.Assert(Count != 0, "SmallList.GetSurePresentItemRef: list should not be empty");
        Debug.Assert(index >= 0 & index < Count, $"SmallList.GetSurePresentItemRef: index {index} should be less than Count {Count}");

        var stackCap = Stack.Capacity;
        if (index < stackCap)
            return ref Stack.GetSurePresentItemRef(index);

        Debug.Assert(Rest != null);
        return ref Rest[index - stackCap];
    }

    /// <summary>Appends the default item to the end of the list and returns the reference to it.</summary>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref T AddDefaultAndGetRef()
    {
        var index = Count++;
        var stackCap = Stack.Capacity;
        if (index < stackCap)
            return ref Stack.GetSurePresentItemRef(index);
        return ref SmallList.AddDefaultAndGetRef(ref Rest, index - stackCap);
    }

    /// <summary>Adds the item to the end of the list aka the Stack.Push. Returns the index of the added item.</summary>
    [MethodImpl((MethodImplOptions)256)]
    public int Add(in T item)
    {
        var index = Count++;
        var stackCap = Stack.Capacity;
        if (index < stackCap)
            Stack.GetSurePresentItemRef(index) = item;
        else
            SmallList.AddDefaultAndGetRef(ref Rest, index - stackCap) = item;
        return index;
    }

    /// <summary>Looks for the item in the list and return its index if found or -1 for the absent item</summary>
    [MethodImpl((MethodImplOptions)256)]
    public int TryGetIndex<TEq>(in T item, TEq eq = default) where TEq : struct, IEq<T>
    {
        if (Count != 0)
        {
            var index = 0;
            foreach (var it in this)
            {
                if (eq.Equals(item, it))
                    return index;
                ++index;
            }
        }
        return -1;
    }

    /// <summary>Returns the index of the found item or appends the item to the end of the list, and returns its index</summary>
    [MethodImpl((MethodImplOptions)256)]
    public int GetIndexOrAdd<TEq>(in T item, TEq eq = default) where TEq : struct, IEq<T>
    {
        var i = TryGetIndex(in item, eq);
        return i != -1 ? i : Add(in item);
    }

    ///<summary>Clears the list, but keeps the already allocated array on heap to reuse in the future</summary>
    [MethodImpl((MethodImplOptions)256)]
    public void Clear()
    {
        Stack = default; // todo: @perf is there way to faster clear items on stack?
        var restCount = Count - Stack.Capacity;
        if (restCount > 0)
        {
            Debug.Assert(Rest != null, "Expecting deeper items are already existing on heap");
            Array.Clear(Rest, 0, restCount);
        }
        Count = 0;
    }

    /// <summary>Returns last present item ref, assumes that the list is not empty!</summary>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref T GetLastSurePresentItem()
    {
        Debug.Assert(Count != 0, "Expecting that the list is not empty");
        return ref GetSurePresentItemRef(Count - 1);
    }

    /// <summary>Removes the last item from the list aka the Stack Pop. Assumes that the list is not empty!</summary>
    [MethodImpl((MethodImplOptions)256)]
    public void RemoveLastSurePresentItem()
    {
        Debug.Assert(Count != 0, "SmallList.RemoveLastSurePresentItem: Expecting that the list is not empty");
        GetSurePresentItemRef(Count - 1) = default;
        --Count;
    }

    /// <summary>Returns an enumerator struct</summary>
    [MethodImpl((MethodImplOptions)256)]
    public SmallListEnumerator<T, TStack> GetEnumerator() => new SmallListEnumerator<T, TStack>(this);
    IEnumerator<T> IEnumerable<T>.GetEnumerator() => GetEnumerator();
    IEnumerator IEnumerable.GetEnumerator() => GetEnumerator();
}

/// <summary>Enumerator on stack, without allocations</summary>
public struct SmallListEnumerator<T, TStack> : IEnumerator<T>, IEnumerator
    where TStack : struct, IStack<T, TStack>
{
    private readonly SmallList<T, TStack> _list;
    private int _index;
    internal SmallListEnumerator(SmallList<T, TStack> list)
    {
        _list = list;
        _index = -1;
    }
    private T _current;
    /// <inheritdoc />
    public T Current => _current;
    object IEnumerator.Current => _current;
    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public bool MoveNext()
    {
        var index = ++_index;
        if (index < _list.Count)
        {
            _current = index < _list.Stack.Capacity
                ? _list.Stack.GetSurePresentItemRef(index)
                : _list.Rest[index - _list.Stack.Capacity];
            return true;
        }
        return false;
    }
    /// <inheritdoc />
    public void Reset() => _index = -1;
    /// <inheritdoc />
    public void Dispose() { }
}

/// <summary>Printable thing via provided printer </summary>
public interface IPrintable
{
    /// <summary>Print to the provided string builder via the provided printer.</summary>
    StringBuilder Print(StringBuilder s, Func<StringBuilder, object, StringBuilder> printer);
}

/// <summary>Produces good enough hash codes for the fields</summary>
public static class Hasher
{
    /// <summary>Combines hashes of two fields</summary>
    public static int Combine<T1, T2>(T1 a, T2 b)
    {
        var bh = b?.GetHashCode() ?? 0;
        if (ReferenceEquals(a, null))
            return bh;
        var ah = a.GetHashCode();
        if (ah == 0)
            return bh;
        return Combine(ah, bh);
    }

    /// <summary>Inspired by System.Tuple.CombineHashCodes</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static int Combine(int h1, int h2)
    {
        unchecked
        {
            return (h1 << 5) + h1 ^ h2;
        }
    }
}

/// <summary>Configures removed key tombstone, equality and hash function for the SmallMap and friends</summary>
public interface IEq<K> : IEqualityComparer<K>
{
    /// <summary>Defines the value of the key indicating the removed entry</summary>
    K GetTombstone();
}

/// <summary>Default comparer using the `object.GetHashCode` and `object.Equals` overloads</summary>
public struct DefaultEq<K> : IEq<K>
{
    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public K GetTombstone() => default;

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public bool Equals(K x, K y) => ReferenceEquals(x, y) || x.Equals(y);

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public int GetHashCode(K key) => key.GetHashCode();
}

/// <summary>Uses the integer itself as hash code and `==` for equality</summary>
public struct IntEq : IEq<int>
{
    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public int GetTombstone() => int.MinValue; // todo: @improve separate the tombstone from the hash

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public bool Equals(int x, int y) => x == y;

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public int GetHashCode(int key) => key;
}

/// <summary>Instances of the RefEq for the often used K</summary>
public static class RefEq
{
    /// <summary>RefEq for object, possibly the only thing you need</summary>
    public static readonly RefEq<object> OfObject = default;
}

// todo: @wip should we even need K here, maybe object implementation is enough?
/// <summary>Uses the `object.GetHashCode` and `object.ReferenceEquals`</summary>
public struct RefEq<K> : IEq<K> where K : class
{
    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public K GetTombstone() => null;

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public bool Equals(K x, K y) => ReferenceEquals(x, y);

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public int GetHashCode(K key) => RuntimeHelpers.GetHashCode(key);
}

/// <summary>Compares via `ReferenceEquals` and gets the hash faster via `RuntimeHelpers.GetHashCode`</summary>
public struct RefEq<A, B> : IEq<(A, B)>
    where A : class
    where B : class
{
    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public (A, B) GetTombstone() => (null, null);

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public bool Equals((A, B) x, (A, B) y) =>
        ReferenceEquals(x.Item1, y.Item1) && ReferenceEquals(x.Item2, y.Item2);

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public int GetHashCode((A, B) key) =>
        Hasher.Combine(RuntimeHelpers.GetHashCode(key.Item1), RuntimeHelpers.GetHashCode(key.Item2));
}

/// <summary>Compares via `ReferenceEquals` and gets the hash faster via `RuntimeHelpers.GetHashCode`</summary>
public struct RefEq<A, B, C> : IEq<(A, B, C)>
    where A : class
    where B : class
    where C : class
{
    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public (A, B, C) GetTombstone() => (null, null, null);

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public bool Equals((A, B, C) x, (A, B, C) y) =>
        ReferenceEquals(x.Item1, y.Item1) && ReferenceEquals(x.Item2, y.Item2) && ReferenceEquals(x.Item3, y.Item3);

    /// <inheritdoc />
    [MethodImpl((MethodImplOptions)256)]
    public int GetHashCode((A, B, C) key) =>
        Hasher.Combine(RuntimeHelpers.GetHashCode(key.Item1), Hasher.Combine(RuntimeHelpers.GetHashCode(key.Item2), RuntimeHelpers.GetHashCode(key.Item3)));
}

/// <summary>Add the Use parameter to `T Method{T}(..., Use{T} _)` to enable type inference for T,
/// by calling it as `var t = Method(..., default(Use{T}))`</summary>
public interface Use<T> { }

/// <summary>Configuration and the tools for the SmallMap and friends</summary>
public static class SmallMap
{
    internal const byte MinFreeCapacityShift = 3; // e.g. for the capacity 16: 16 >> 3 => 2, 12.5% of the free hash slots (it does not mean the entries free slot)
    internal const byte MinHashesCapacityBitShift = 4; // 1 << 4 == 16
    internal const int IndexMask = (1 << MinHashesCapacityBitShift) - 1; // 0b00000000000000000000000000001111
    /// <summary>Upper hash bits spent on storing the probes, e.g. 5 bits mean 31 probes max.</summary>
    public const byte ProbeBits = 5;
    internal const byte NotShiftedProbeCountMask = (1 << ProbeBits) - 1; // 0b00000000000000000000000000011111
    // 27, so the upper 5 bits are used for the probe count
    internal const byte ProbeCountShift = 32 - ProbeBits;
    // ~0b11111000000000000000000000000000 -> 0b00000111111111111111111111111111
    internal const int HashAndIndexMask = ~(NotShiftedProbeCountMask << ProbeCountShift);
    // Window with the hash mask without the lead ProbeMask and closing IndexMask 0b00000111111111111111111111110000
    internal const int HashMask = HashAndIndexMask & ~IndexMask;

    /// <summary>Represent a keyed entry stored in the SmallMap.
    /// Its implementation struct may include the additional Value for the Map or just the Key for the Set.
    /// The implementation may also decide to make Value readonly or writable for the in-place update</summary>
    public interface IEntry<K>
    {
        /// <summary>Returns the key of the payload</summary>
        K Key { get; internal set; }
    }

    /// <summary>Holds a single entry consisting of key and value. 
    /// Value may be set or changed but the key is set in stone (by construction).</summary>
    [DebuggerDisplay("{Key?.ToString()}->{Value}")]
    public struct Entry<K, V> : IEntry<K>
    {
        /// <summary>The readonly key</summary>
        public K Key { get; set; }
        /// <summary>The mutable value</summary>
        public V Value;
        /// <summary>Construct with the key and default value</summary>
        public Entry(K key) => Key = key;
        /// <summary>Construct with the key and value</summary>
        public Entry(K key, V value)
        {
            Key = key;
            Value = value;
        }
    }

    /// <summary>The entry with just a key.
    /// When used with the SmallMap it may represent a Set without wasting the space for the absent value</summary>
    [DebuggerDisplay("{Key?.ToString()}")]
    public struct Entry<K> : IEntry<K>
    {
        /// <summary>The readonly key</summary>
        public K Key { get; set; }
        /// <summary>Construct with the key and default value</summary>
        public Entry(K key) => Key = key;
    }

    /// <summary>Binary representation of the `int`</summary>
    public static string ToB(int x) => System.Convert.ToString(x, 2).PadLeft(32, '0');

    [MethodImpl((MethodImplOptions)256)]
#if NET7_0_OR_GREATER
    internal static ref int NextHashRef(ref int start, int distance) => ref Unsafe.Add(ref start, distance);
#else
    internal static ref int NextHashRef(ref int[] start, int distance) => ref start[distance];
#endif

    [MethodImpl((MethodImplOptions)256)]
#if NET7_0_OR_GREATER
    internal static int NextHash(ref int start, int distance) => Unsafe.Add(ref start, distance);
#else
    internal static int NextHash(ref int[] start, int distance) => start[distance];
#endif

    /// <summary>Abstraction to configure your own entries data structure. Check the derived types for the examples</summary>
    public interface IEntries<K, TEntry, TEq>
        where TEntry : struct, IEntry<K>
        where TEq : IEq<K>
    {
        /// <summary>Initializes the entries storage to the specified capacity</summary>
        void Init(int capacityPowerOfTwoPlease);

        /// <summary>Returns the reference to entry by its index, index should map to the present/non-removed entry</summary>
        ref TEntry GetSurePresentEntryRef(int index);

        /// <summary>Adds the key at the "end" of entries - so the order of addition is preserved.</summary>
        ref TEntry AddKeyAndGetEntryRef(K key, int index);
    }

    internal const int MinEntriesCapacity = 2;

    /// <summary>For now to use in the Set as a value</summary>
    public readonly struct NoValue { }

    /// <summary>Stores the entries in a single dynamically reallocated growing array</summary>
    [DebuggerDisplay("{Capacity:_entries?.Length ?? 0} of {_entries?[0]}, {_entries?[1]}, ...")]
    public struct SingleArrayEntries<K, TEntry, TEq> : IEntries<K, TEntry, TEq>
        where TEntry : struct, IEntry<K>
        where TEq : struct, IEq<K>
    {
        internal TEntry[] _entries;

        /// <inheritdoc/>
        public void Init(int capacityPowerOfTwoPlease) =>
            _entries = new TEntry[capacityPowerOfTwoPlease];

        /// <inheritdoc/>
        [MethodImpl((MethodImplOptions)256)]
        public ref TEntry GetSurePresentEntryRef(int index) =>
            ref _entries.GetSurePresentItemRef(index);

        /// <inheritdoc/>
        [MethodImpl((MethodImplOptions)256)]
        public ref TEntry AddKeyAndGetEntryRef(K key, int index)
        {
            if (index == _entries.Length)
                Array.Resize(ref _entries, index << 1);

            ref var e = ref _entries.GetSurePresentItemRef(index);
            e.Key = key;
            return ref e;
        }
    }

    /// <summary>Lookup for the K in the TStackEntries, first by calculating it hash with TEq and searching the hash in the TStackHashes</summary>
    public static ref TEntry TryGetEntryRef<K, TEntry, TEq, TCap, TStackHashes, TStackEntries>(
        this ref TStackEntries entries, ref TStackHashes hashes, K key, out bool found,
        TEq eq = default, TCap cap = default, Use<TEntry> _ = default)
        where TEntry : struct, IEntry<K>
        where TEq : struct, IEq<K>
        where TStackHashes : struct, IStack<int, TCap, TStackHashes>
        where TStackEntries : struct, IStack<TEntry, TCap, TStackEntries>
        where TCap : struct, ISize2Plus
    {
        var hash = eq.GetHashCode(key);

#if NET8_0_OR_GREATER
        if (cap.Size >= 8 & Vector256.IsHardwareAccelerated)
        {
            var vHash = Vector256.Create(hash);
            var vHashes = MemoryMarshal.Cast<int, Vector256<int>>(hashes.AsSpan());
            var i = 0;
            foreach (var vCurr in vHashes)
            {
                var vMatches = Vector256.Equals(vCurr, vHash);
                var matches = Vector256.ExtractMostSignificantBits(vMatches);
                while (matches != 0)
                {
                    var matchIndex = System.Numerics.BitOperations.TrailingZeroCount(matches);

                    ref var entry = ref entries.GetSurePresentItemRef(i + matchIndex);
                    if (found = eq.Equals(entry.Key, key))
                        return ref entry;

                    // Clear lower bits up to and including the first set bit, afaik it can be hw accelerated 
                    // 0b0001_1000 & (0b0001_1000 - 1) -> & 0b0001_1000 & 0b0001_0111 -> 0b0001_0000 
                    matches &= matches - 1;
                }

                i += Vector256<int>.Count;
            }

            found = false;
            return ref RefTools<TEntry>.GetNullRef();
        }
#endif

        for (var i = 0; i < hashes.Capacity; ++i)
        {
            var h = hashes.GetSurePresentItemRef(i);
            if (h == hash)
            {
                ref var entry = ref entries.GetSurePresentItemRef(i);
                if (found = eq.Equals(entry.Key, key))
                    return ref entry;
            }
        }

        found = false;
        return ref RefTools<TEntry>.GetNullRef();
    }

    /// <summary>Gets the ref to the existing entry.Value by the provided key (found == true),
    /// or adds a new entry (found == false) and returns it.Value by ref. 
    /// So the method always return a non-null ref to the value, either existing or added</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref V AddOrGetValueRef<K, V, TEq, TStackCap, TStackHashes, TStackEntries, TEntries>(
        this ref SmallMap<K, Entry<K, V>, TEq, TStackCap, TStackHashes, TStackEntries, TEntries> map, K key, out bool found)
        where TEq : struct, IEq<K>
        where TStackCap : struct, ISize2Plus
        where TStackHashes : struct, IStack<int, TStackCap, TStackHashes>
        where TStackEntries : struct, IStack<Entry<K, V>, TStackCap, TStackEntries>
        where TEntries : struct, IEntries<K, Entry<K, V>, TEq> =>
        ref map.AddOrGetEntryRef(key, out found).Value;

    /// <summary>Adds an entry for sure absent key.
    /// Provides the performance in scenarios where you look for the present key, and using it, and if ABSENT then add the new one.
    /// So this method optimized NOT to look for the present item for the second time</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref V AddSureAbsentDefaultAndGetRef<K, V, TEq, TStackCap, TStackHashes, TStackEntries, TEntries>(
        this ref SmallMap<K, Entry<K, V>, TEq, TStackCap, TStackHashes, TStackEntries, TEntries> map, K key)
        where TEq : struct, IEq<K>
        where TStackCap : struct, ISize2Plus
        where TStackHashes : struct, IStack<int, TStackCap, TStackHashes>
        where TStackEntries : struct, IStack<Entry<K, V>, TStackCap, TStackEntries>
        where TEntries : struct, IEntries<K, Entry<K, V>, TEq>
        => ref map.AddSureAbsentDefaultEntryAndGetRef(key).Value;

    /// <summary>Lookups for the stored entry by key. Returns the ref to the found entry.Value or the null ref</summary>
    [MethodImpl((MethodImplOptions)256)]
    public static ref V TryGetValueRef<K, V, TEq, TStackCap, TStackHashes, TStackEntries, TEntries>(
        this ref SmallMap<K, Entry<K, V>, TEq, TStackCap, TStackHashes, TStackEntries, TEntries> map, K key, out bool found)
        where TEq : struct, IEq<K>
        where TStackCap : struct, ISize2Plus
        where TStackHashes : struct, IStack<int, TStackCap, TStackHashes>
        where TStackEntries : struct, IStack<Entry<K, V>, TStackCap, TStackEntries>
        where TEntries : struct, IEntries<K, Entry<K, V>, TEq>
    {
        ref var e = ref map.TryGetEntryRef(key, out found);
        if (found) return ref e.Value;
        return ref RefTools<V>.GetNullRef();
    }
}

// todo: @improve ? how/where to add SIMD to improve CPU utilization but not losing perf for smaller sizes
/// <summary>
/// Fast and less-allocating hash map without thread safety nets. Please measure it in your own use case before use.
/// It is configurable in regard of hash calculation/equality via `TEq` type parameter and 
/// in regard of key-value storage via `TEntries` type parameter.
/// 
/// Details:
/// - Implemented as a struct so that the empty/default map does not allocate on heap
/// - Hashes and key-values are the separate collections enabling better cash locality and faster performance (data-oriented design)
/// - No SIMD for now to avoid complexity and costs for the smaller maps, so the map is more fit for the smaller sizes.
/// - Provides the "stable" enumeration of the entries in the added order
/// - The TryRemove method removes the hash but replaces the key-value entry with the tombstone key and the default value.
/// For instance, for the `RefEq` the tombstone is <see langword="null"/>. You may redefine it in the `IEq{K}.GetTombstone()` implementation.
/// 
/// </summary>
[DebuggerDisplay("{Count} of {_e0}, {_e1}, {_e2}, {_e3}, ...")]
public struct SmallMap<K, TEntry, TEq, TStackCap, TStackHashes, TStackEntries, TEntries>
    where TEntry : struct, IEntry<K>
    where TEq : struct, IEq<K>
    where TStackCap : struct, ISize2Plus
    where TStackHashes : struct, IStack<int, TStackCap, TStackHashes>
    where TStackEntries : struct, IStack<TEntry, TStackCap, TStackEntries>
    where TEntries : struct, IEntries<K, TEntry, TEq>
{
    internal byte _capacityBitShift;
    internal int _count;

    // The _packedHashesAndIndexes elements are of `Int32` with the bits split as following:
    // 00010|000...110|01101
    // |     |         |- The index into the _entries structure, 0-based. The index bit count (indexMask) is the hashes capacity - 1.
    // |     |         | This part of the erased hash is used to get the ideal index into the hashes array, so later this part of hash may be restored from the hash index and its probes.
    // |     |- The remaining middle bits of the original hash
    // |- 5 (MaxProbeBits) high bits of the Probe count, with the minimal value of b00001 indicating the non-empty slot.
    internal int[] _packedHashesAndIndexes;

#pragma warning disable IDE0044 // it tries to make entries readonly but they should stay modify-able to prevent its defensive struct copying
    internal TEntries _entries;
#pragma warning restore IDE0044
#pragma warning disable CS0649 // Field 'SmallMap<K, V, TEq, TStack, TEntries>.Stack' is never assigned to, and will always have its default value
    internal TStackHashes StackHashes;
    internal TStackEntries StackEntries;
#pragma warning restore CS0649

    /// <summary>Capacity bits</summary>
    public int CapacityBitShift => _capacityBitShift;

    /// <summary>Access to the hashes and indexes</summary>
    public int[] PackedHashesAndIndexes => _packedHashesAndIndexes;

    /// <summary>Number of entries in the map</summary>
    public int Count => _count;

    /// <summary>Access to the key-value entries</summary>
    public TEntries Entries => _entries;

    /// <summary>Capacity calculates as `1 leftShift capacityBitShift`</summary>
    public SmallMap(byte capacityBitShift)
    {
        _capacityBitShift = capacityBitShift;

        // the overflow tail to the hashes is the size of log2N where N==capacityBitShift, 
        // it is probably fine to have the check for the overflow of capacity because it will be mis-predicted only once at the end of loop (it even rarely for the lookup)
        _packedHashesAndIndexes = new int[1 << capacityBitShift];
        _entries = default;
        _entries.Init(capacityBitShift);
    }

    ///<summary>Get the value ref by the entry index. Also the index corresponds to entry adding order.
    /// Important: it does not check the index bounds, so you need to check that the index is from 0 to map.Count-1</summary>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref TEntry GetSurePresentEntryRef(int index)
    {
        Debug.Assert(index >= 0);
        Debug.Assert(index < _count);
        if (index >= StackEntries.Capacity)
            return ref _entries.GetSurePresentEntryRef(index - StackEntries.Capacity);
        return ref StackEntries.GetSurePresentItemRef(index);
    }

    [UnscopedRef]
    private ref TEntry AddOrGetRefInEntries(K key, out bool found)
    {
        // if the free space is less than 1/8 of capacity (12.5%) then Resize
        var indexMask = (1 << _capacityBitShift) - 1;
        if (indexMask - _count <= (indexMask >>> MinFreeCapacityShift))
            indexMask = ResizeHashes(indexMask);

        var hash = default(TEq).GetHashCode(key);
        var hashMiddleMask = HashAndIndexMask & ~indexMask;
        var hashMiddle = hash & hashMiddleMask;
        var hashIndex = hash & indexMask;

#if NET7_0_OR_GREATER
        ref var hashesAndIndexes = ref MemoryMarshal.GetArrayDataReference(_packedHashesAndIndexes);
#else
        var hashesAndIndexes = _packedHashesAndIndexes;
#endif
        ref var h = ref NextHashRef(ref hashesAndIndexes, hashIndex);

        // 1. Skip over hashes with the bigger and equal probes. The hashes with bigger probes overlapping from the earlier ideal positions
        var probes = 1;
        while ((h >>> ProbeCountShift) >= probes)
        {
            // 2. For the equal probes check for equality the hash middle part, and update the entry if the keys are equal too 
            if (((h >>> ProbeCountShift) == probes) & ((h & hashMiddleMask) == hashMiddle))
            {
                ref var e = ref GetSurePresentEntryRef(h & indexMask);
                if (found = default(TEq).Equals(e.Key, key))
                    return ref e;
            }
            h = ref NextHashRef(ref hashesAndIndexes, ++hashIndex & indexMask);
            ++probes;
        }
        found = false;

        // 3. We did not find the hash and therefore the key, so insert the new entry
        var hRobinHooded = h;
        h = (probes << ProbeCountShift) | hashMiddle | _count;

        // 4. If the robin hooded hash is empty then we stop
        // 5. Otherwise we steal the slot with the smaller probes
        probes = hRobinHooded >>> ProbeCountShift;
        while (hRobinHooded != 0)
        {
            h = ref NextHashRef(ref hashesAndIndexes, ++hashIndex & indexMask);
            if ((h >>> ProbeCountShift) < ++probes)
            {
                var tmp = h;
                h = (probes << ProbeCountShift) | (hRobinHooded & HashAndIndexMask);
                hRobinHooded = tmp;
                probes = hRobinHooded >>> ProbeCountShift;
            }
        }

        return ref _entries.AddKeyAndGetEntryRef(key, (_count++) - StackEntries.Capacity);
    }

    private void AddJustHashAndEntryIndexWithoutResizing(int hash, int index)
    {
        var hashIndex = hash & IndexMask;

#if NET7_0_OR_GREATER
        ref var hashesAndIndexes = ref MemoryMarshal.GetArrayDataReference(_packedHashesAndIndexes);
#else
        var hashesAndIndexes = _packedHashesAndIndexes;
#endif
        // 1. Skip over hashes with the bigger and equal probes. The hashes with bigger probes overlapping from the earlier ideal positions
        ref var h = ref NextHashRef(ref hashesAndIndexes, hashIndex);
        var probes = 1;
        while ((h >>> ProbeCountShift) >= probes)
        {
            h = ref NextHashRef(ref hashesAndIndexes, ++hashIndex & IndexMask);
            ++probes;
        }

        // 3. We did not find the hash and therefore the key, so insert the new entry
        var hRobinHooded = h;
        h = (probes << ProbeCountShift) | (hash & HashMask) | index;

        // 4. If the robin hooded hash is empty then we stop
        // 5. Otherwise we steal the slot with the smaller probes
        probes = hRobinHooded >>> ProbeCountShift;
        while (hRobinHooded != 0)
        {
            h = ref NextHashRef(ref hashesAndIndexes, ++hashIndex & IndexMask);
            if ((h >>> ProbeCountShift) < ++probes)
            {
                var tmp = h;
                h = (probes << ProbeCountShift) | (hRobinHooded & HashAndIndexMask);
                hRobinHooded = tmp;
                probes = hRobinHooded >>> ProbeCountShift;
            }
        }
    }

    /// <summary>Gets the ref to the existing entry by the provided key (found == true),
    /// or adds a new entry (found == false) and returns it by ref</summary>
    [UnscopedRef]
    public ref TEntry AddOrGetEntryRef(K key, out bool found)
    {
        if (_count > StackEntries.Capacity)
            return ref AddOrGetRefInEntries(key, out found);

        // Linear search in stack (which has a few items) by comparing the keys without calculating the hashes
        // Saving on the hash calculation. Losing on the bigger number of comparisons.
        for (var i = 0; i < _count; ++i)
        {
            ref var e = ref GetSurePresentEntryRef(i);
            if (found = default(TEq).Equals(e.Key, key))
                return ref e;
        }
        found = false;

        // Add the new entry to the stack if there is still space in stack
        if (_count < StackEntries.Capacity)
        {
            var newIndex = _count++;
            ref var newEntry = ref StackEntries.GetSurePresentItemRef(newIndex);
            newEntry.Key = key;
            return ref newEntry;
        }

        // Now all capacity of the stack is used.
        // To avoid double work always going linearly through the Stack with the comparison,
        // let's calculate the hash of the keys stored on stack and put them 
        // to the usual HashMap packed hashes and indexes array for the promised O(1) lookup.
        // But the values are remaining on the Stack, and for the found index of the entry we use the GetSurePresentItemRef(index) 
        // to get the value reference either from the Stack or the Entries.
        // So the values on the stack are guarantied to be stable from the beginning of the map creation, 
        // because they are not copied when the Entries need to Resize (depending on the TEntries implementation). 

        _capacityBitShift = MinHashesCapacityBitShift;
        _packedHashesAndIndexes = new int[1 << MinHashesCapacityBitShift];

        for (var i = 0; i < StackEntries.Capacity; ++i)
            AddJustHashAndEntryIndexWithoutResizing(default(TEq).GetHashCode(GetSurePresentEntryRef(i).Key), i);

        AddJustHashAndEntryIndexWithoutResizing(default(TEq).GetHashCode(key), StackEntries.Capacity);

        _count = StackEntries.Capacity + 1; // +1 because we added the new key
        _entries.Init(StackEntries.Capacity); // Give the heap entries the same initial capacity as Stack, effectively doubling the capacity
        return ref _entries.AddKeyAndGetEntryRef(key, 0); // add the new key to the entries with the 0 index in the entries
    }

    [UnscopedRef]
    private ref TEntry AddSureAbsentDefaultAndGetRefInEntries(K key)
    {
        // if the free space is less than 1/8 of capacity (12.5%) then Resize
        var indexMask = (1 << _capacityBitShift) - 1;
        if (indexMask - _count <= (indexMask >>> MinFreeCapacityShift))
            indexMask = ResizeHashes(indexMask);

        var hash = default(TEq).GetHashCode(key);
        var hashIndex = hash & indexMask;

#if NET7_0_OR_GREATER
        ref var hashesAndIndexes = ref MemoryMarshal.GetArrayDataReference(_packedHashesAndIndexes);
#else
        var hashesAndIndexes = _packedHashesAndIndexes;
#endif
        ref var h = ref NextHashRef(ref hashesAndIndexes, hashIndex);

        // 1. Skip over hashes with the bigger and equal probes. The hashes with bigger probes overlapping from the earlier ideal positions
        var probes = 1;
        while ((h >>> ProbeCountShift) >= probes)
        {
            h = ref NextHashRef(ref hashesAndIndexes, ++hashIndex & indexMask);
            ++probes;
        }

        // 3. We did not find the hash and therefore the key, so insert the new entry
        var hRobinHooded = h;
        h = (probes << ProbeCountShift) | (hash & HashAndIndexMask & ~indexMask) | _count;

        // 4. If the robin hooded hash is empty then we stop
        // 5. Otherwise we steal the slot with the smaller probes
        probes = hRobinHooded >>> ProbeCountShift;
        while (hRobinHooded != 0)
        {
            h = ref NextHashRef(ref hashesAndIndexes, ++hashIndex & indexMask);
            if ((h >>> ProbeCountShift) < ++probes)
            {
                var tmp = h;
                h = (probes << ProbeCountShift) | (hRobinHooded & HashAndIndexMask);
                hRobinHooded = tmp;
                probes = hRobinHooded >>> ProbeCountShift;
            }
        }

        return ref _entries.AddKeyAndGetEntryRef(key, (_count++) - StackEntries.Capacity);
    }

    /// <summary>Adds an entry for sure absent key.
    /// Provides the performance in scenarios where you look for the present key, and using it, and if ABSENT then add the new one.
    /// So this method optimized NOT to look for the present item for the second time</summary>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref TEntry AddSureAbsentDefaultEntryAndGetRef(K key)
    {
        if (_count > StackEntries.Capacity)
            return ref AddSureAbsentDefaultAndGetRefInEntries(key);

        // Add the new entry to the stack if there is still space in stack
        if (_count < StackEntries.Capacity)
        {
            var newIndex = _count++;
            ref var newEntry = ref StackEntries.GetSurePresentItemRef(newIndex);
            newEntry.Key = key;
            return ref newEntry;
        }

        _capacityBitShift = MinHashesCapacityBitShift;
        _packedHashesAndIndexes = new int[1 << MinHashesCapacityBitShift];

        for (var i = 0; i < StackEntries.Capacity; ++i)
            AddJustHashAndEntryIndexWithoutResizing(default(TEq).GetHashCode(GetSurePresentEntryRef(i).Key), i);

        AddJustHashAndEntryIndexWithoutResizing(default(TEq).GetHashCode(key), StackEntries.Capacity);

        _count = StackEntries.Capacity + 1; // +1 because we added the new key
        _entries.Init(StackEntries.Capacity); // Give the heap entries the same initial capacity as Stack, effectively doubling the capacity
        return ref _entries.AddKeyAndGetEntryRef(key, 0); // add the new key to the entries with the 0 index in the entries
    }

    /// <summary>Lookups for the stored key. If found true, otherwise false</summary>
    [MethodImpl((MethodImplOptions)256)]
    public bool ContainsKey(K key)
    {
        if (_count > StackEntries.Capacity)
        {
            TryGetRefInEntries(key, out var found);
            return found;
        }

        for (var i = 0; i < _count; ++i)
            if (default(TEq).Equals(key, GetSurePresentEntryRef(i).Key))
                return true;

        return false;
    }

    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    internal ref TEntry TryGetRefInEntries(K key, out bool found)
    {
        var hash = default(TEq).GetHashCode(key);

        var indexMask = (1 << _capacityBitShift) - 1;
        var hashMiddleMask = HashAndIndexMask & ~indexMask;
        var hashMiddle = hash & hashMiddleMask;
        var hashIndex = hash & indexMask;

#if NET7_0_OR_GREATER
        ref var hashesAndIndexes = ref MemoryMarshal.GetArrayDataReference(_packedHashesAndIndexes);
#else
        var hashesAndIndexes = _packedHashesAndIndexes;
#endif

        var h = NextHash(ref hashesAndIndexes, hashIndex);

        // 1. Skip over hashes with the bigger and equal probes. The hashes with bigger probes overlapping from the earlier ideal positions
        var probes = 1;
        while ((h >>> ProbeCountShift) >= probes)
        {
            // 2. For the equal probes check for equality the hash middle part, and update the entry if the keys are equal too 
            if (((h >>> ProbeCountShift) == probes) & ((h & hashMiddleMask) == hashMiddle))
            {
                ref var e = ref GetSurePresentEntryRef(h & indexMask);
                if (found = default(TEq).Equals(e.Key, key))
                    return ref e;
            }

            h = NextHash(ref hashesAndIndexes, ++hashIndex & indexMask);
            ++probes;
        }

        found = false;
        return ref RefTools<TEntry>.GetNullRef();
    }

    /// <summary>Lookups for the stored entry by key. Returns the ref to the found entry or the null ref</summary>
    [UnscopedRef]
    [MethodImpl((MethodImplOptions)256)]
    public ref TEntry TryGetEntryRef(K key, out bool found)
    {
        if (_count > StackEntries.Capacity)
            return ref TryGetRefInEntries(key, out found);

        for (var i = 0; i < _count; ++i)
        {
            ref var e = ref GetSurePresentEntryRef(i);
            if (found = default(TEq).Equals(key, e.Key))
                return ref e;
        }

        found = false;
        return ref RefTools<TEntry>.GetNullRef();
    }

    internal int ResizeHashes(int indexMask)
    {
        var oldCapacity = indexMask + 1;
        var newHashAndIndexMask = HashAndIndexMask & ~oldCapacity;
        var newIndexMask = (indexMask << 1) | 1;

        var newHashesAndIndexes = new int[oldCapacity << 1];

#if NET7_0_OR_GREATER
        ref var newHashes = ref MemoryMarshal.GetArrayDataReference(newHashesAndIndexes);
        ref var oldHashes = ref MemoryMarshal.GetArrayDataReference(_packedHashesAndIndexes);
        var oldHash = oldHashes;
#else
        var newHashes = newHashesAndIndexes;
        var oldHashes = _packedHashesAndIndexes;
        var oldHash = oldHashes[0];
#endif
        // Overflow segment is wrapped-around hashes and! the hashes at the beginning robin hooded by the wrapped-around hashes
        var i = 0;
        while ((oldHash >>> ProbeCountShift) > 1)
            oldHash = NextHash(ref oldHashes, ++i);

        var oldCapacityWithOverflowSegment = i + oldCapacity;
        while (true)
        {
            if (oldHash != 0)
            {
                // get the new hash index from the old one with the next bit equal to the `oldCapacity`
                var indexWithNextBit = (oldHash & oldCapacity) | (((i + 1) - (oldHash >>> ProbeCountShift)) & indexMask);

                // no need for robin-hooding because we already did it for the old hashes and now just filling the hashes into the new array which are already in order
                var probes = 1;
                ref var newHash = ref NextHashRef(ref newHashes, indexWithNextBit);
                while (newHash != 0)
                {
                    newHash = ref NextHashRef(ref newHashes, ++indexWithNextBit & newIndexMask);
                    ++probes;
                }
                newHash = (probes << ProbeCountShift) | (oldHash & newHashAndIndexMask);
            }
            if (++i >= oldCapacityWithOverflowSegment)
                break;

            oldHash = NextHash(ref oldHashes, i & indexMask);
        }
        ++_capacityBitShift;
        _packedHashesAndIndexes = newHashesAndIndexes;
        return newIndexMask;
    }
}

/// <summary>Holds the Map with 4 items on stack. Minimizes the number of type arguments required to be specified</summary>
public struct SmallMap4<K, V, TEq>() where TEq : struct, IEq<K>
{
    /// <summary>Map with 4 elements on stack and entries baked by the single array</summary> 
    public SmallMap<K, SmallMap.Entry<K, V>, TEq, Size4, Stack4<int>, Stack4<SmallMap.Entry<K, V>>, SmallMap.SingleArrayEntries<K, SmallMap.Entry<K, V>, TEq>> Map;
}

/// <summary>Holds the Map with 8 items on stack. Minimizes the number of type arguments required to be specified</summary>
public struct SmallMap8<K, V, TEq>() where TEq : struct, IEq<K>
{
    /// <summary>Map with 8 elements on stack and entries baked by the single array</summary> 
    public SmallMap<K, SmallMap.Entry<K, V>, TEq, Size8, Stack8<int>, Stack8<SmallMap.Entry<K, V>>, SmallMap.SingleArrayEntries<K, SmallMap.Entry<K, V>, TEq>> Map;
}

/// <summary>Holds the Map with 16 items on stack. Minimizes the number of type arguments required to be specified</summary>
public struct SmallMap16<K, V, TEq>() where TEq : struct, IEq<K>
{
    /// <summary>Map with 16 elements on stack and entries baked by the single array</summary> 
    public SmallMap<K, SmallMap.Entry<K, V>, TEq, Size16, Stack16<int>, Stack16<SmallMap.Entry<K, V>>, SmallMap.SingleArrayEntries<K, SmallMap.Entry<K, V>, TEq>> Map;
}

/// <summary>Holds the Set with 4 items on stack. Minimizes the number of type arguments required to be specified</summary>
public struct SmallSet4<K, TEq>() where TEq : struct, IEq<K>
{
    /// <summary>Set with 4 keys on stack and entries baked by the single array</summary> 
    public SmallMap<K, SmallMap.Entry<K>, TEq, Size4, Stack4<int>, Stack4<SmallMap.Entry<K>>, SmallMap.SingleArrayEntries<K, SmallMap.Entry<K>, TEq>> Set;
}

/// <summary>Holds the Set with 8 items on stack. Minimizes the number of type arguments required to be specified</summary>
public struct SmallSet8<K, TEq>() where TEq : struct, IEq<K>
{
    /// <summary>Set with 8 keys on stack and entries baked by the single array</summary> 
    public SmallMap<K, SmallMap.Entry<K>, TEq, Size8, Stack8<int>, Stack8<SmallMap.Entry<K>>, SmallMap.SingleArrayEntries<K, SmallMap.Entry<K>, TEq>> Set;
}

/// <summary>Holds the Set with 16 items on stack. Minimizes the number of type arguments required to be specified</summary>
public struct SmallSet16<K, TEq>() where TEq : struct, IEq<K>
{
    /// <summary>Set with 16 keys on stack and entries baked by the single array</summary> 
    public SmallMap<K, SmallMap.Entry<K>, TEq, Size16, Stack16<int>, Stack16<SmallMap.Entry<K>>, SmallMap.SingleArrayEntries<K, SmallMap.Entry<K>, TEq>> Set;
}

#nullable restore